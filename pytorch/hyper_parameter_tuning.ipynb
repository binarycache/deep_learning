{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from data_loader import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import model\n",
    "torch.set_printoptions(linewidth=120)\n",
    "from utils import *\n",
    "from collections import OrderedDict\n",
    "from run_builder import RunBuilder\n",
    "from run_manager import RunManager\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/data/github/deep_learning/pytorch/hyper_parameter_tuning.ipynb Cell 3'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://localhost:3000/data/github/deep_learning/pytorch/hyper_parameter_tuning.ipynb#ch0000001vscode-remote?line=8'>9</a>\u001b[0m comment \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m{\u001b[39;00mrun\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://localhost:3000/data/github/deep_learning/pytorch/hyper_parameter_tuning.ipynb#ch0000001vscode-remote?line=10'>11</a>\u001b[0m data_loader \u001b[39m=\u001b[39m DataLoader(\u001b[39m'\u001b[39m\u001b[39mfashion_mnist\u001b[39m\u001b[39m'\u001b[39m,batch_size\u001b[39m=\u001b[39mrun\u001b[39m.\u001b[39mbatch_size)\n\u001b[0;32m---> <a href='vscode-notebook-cell://localhost:3000/data/github/deep_learning/pytorch/hyper_parameter_tuning.ipynb#ch0000001vscode-remote?line=11'>12</a>\u001b[0m network \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mNetwork()\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://localhost:3000/data/github/deep_learning/pytorch/hyper_parameter_tuning.ipynb#ch0000001vscode-remote?line=12'>13</a>\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(\n\u001b[1;32m     <a href='vscode-notebook-cell://localhost:3000/data/github/deep_learning/pytorch/hyper_parameter_tuning.ipynb#ch0000001vscode-remote?line=13'>14</a>\u001b[0m     network\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mrun\u001b[39m.\u001b[39mlr\n\u001b[1;32m     <a href='vscode-notebook-cell://localhost:3000/data/github/deep_learning/pytorch/hyper_parameter_tuning.ipynb#ch0000001vscode-remote?line=14'>15</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://localhost:3000/data/github/deep_learning/pytorch/hyper_parameter_tuning.ipynb#ch0000001vscode-remote?line=16'>17</a>\u001b[0m m\u001b[39m.\u001b[39mbegin_run(run, network, data_loader)\n",
      "File \u001b[0;32m/data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:899\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=894'>895</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=895'>896</a>\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m    <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=896'>897</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=898'>899</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m/data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:570\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=567'>568</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=568'>569</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=569'>570</a>\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=571'>572</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=572'>573</a>\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=573'>574</a>\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=574'>575</a>\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=579'>580</a>\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=580'>581</a>\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:593\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=588'>589</a>\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=589'>590</a>\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=590'>591</a>\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=591'>592</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=592'>593</a>\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=593'>594</a>\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=594'>595</a>\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py:897\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=893'>894</a>\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m    <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=894'>895</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=895'>896</a>\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/nn/modules/module.py?line=896'>897</a>\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "File \u001b[0;32m/data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/cuda/__init__.py:214\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/cuda/__init__.py?line=209'>210</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/cuda/__init__.py?line=210'>211</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/cuda/__init__.py?line=211'>212</a>\u001b[0m \u001b[39m# This function throws if there's a driver initialization error, no GPUs\u001b[39;00m\n\u001b[1;32m    <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/cuda/__init__.py?line=212'>213</a>\u001b[0m \u001b[39m# are found or any other error occurs\u001b[39;00m\n\u001b[0;32m--> <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/cuda/__init__.py?line=213'>214</a>\u001b[0m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_cuda_init()\n\u001b[1;32m    <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/cuda/__init__.py?line=214'>215</a>\u001b[0m \u001b[39m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/cuda/__init__.py?line=215'>216</a>\u001b[0m \u001b[39m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/cuda/__init__.py?line=216'>217</a>\u001b[0m \u001b[39m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    <a href='file:///data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/cuda/__init__.py?line=217'>218</a>\u001b[0m _tls\u001b[39m.\u001b[39mis_initializing \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "params = OrderedDict(\n",
    "    lr = [.01, .001]\n",
    "    ,batch_size = [1000, 10000]\n",
    ")\n",
    "\n",
    "m = RunManager()\n",
    "\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    comment = f'-{run}'\n",
    "    \n",
    "    data_loader = DataLoader('fashion_mnist',batch_size=run.batch_size)\n",
    "    network = model.Network().to(device)\n",
    "    optimizer = optim.Adam(\n",
    "        network.parameters(), lr=run.lr\n",
    "    )\n",
    "    \n",
    "    m.begin_run(run, network, data_loader)\n",
    "\n",
    "    for epoch in range(3):\n",
    "        m.begin_epoch()\n",
    "        \n",
    "        for batch in data_loader.train_loader:\n",
    "            images = batch[0].to(device)\n",
    "            labels = batch[1].to(device) # Get Batch\n",
    "            preds = network(images) # Pass Batch\n",
    "            loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "            optimizer.zero_grad() # Zero Gradients\n",
    "            loss.backward() # Calculate Gradients\n",
    "            optimizer.step() # Update Weights\n",
    "\n",
    "            m.track_loss(loss, batch)\n",
    "            m.track_num_correct(preds, labels)\n",
    "        m.end_epoch()\n",
    "    m.end_run()\n",
    "m.save('results')\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c207b5e043e2b6ee029cb1f3c7633378ed9ad895d49c50d408b3ba611a8a833e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
