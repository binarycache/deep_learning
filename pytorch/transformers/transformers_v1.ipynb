{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62750b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f99ee3",
   "metadata": {},
   "source": [
    "by applying a linear transformation to the original input vector. In other words, we add three kÃ—k weight matrices ğ–q, ğ–k,ğ–v and compute three linear transformations of each xi, for the three different parts of the self attention:\n",
    "\n",
    "ğªi=ğ–qğ±iğ¤i=ğ–kğ±iğ¯i=ğ–vğ±i\n",
    "wâ€²ijwijğ²i=ğªiTğ¤j=softmax(wâ€²ij)=âˆ‘jwijğ¯j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ae2392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing own attention \n",
    "\n",
    "class Transformer():\n",
    "    \n",
    "    \n",
    "    def __init__():\n",
    "        pass\n",
    "\n",
    "    def self_attention(self, x):\n",
    "        \"\"\"Function to apply self attention to the vector x.\n",
    "        Arguments\n",
    "        -------------------------\n",
    "        Shape of x: batch_size, t, k where t is the no. of vectors \n",
    "                    and k is the size of each vector\n",
    "\n",
    "        Returns:\n",
    "        --------------------------\n",
    "        \n",
    "        \n",
    "        Notes:\n",
    "        --------------------------\n",
    "        Assume we have a tensor of size (batch_size, t vectors, k (dimension of each vector))\n",
    "        k is fixed as the size of the embedding layer and the encoding layer is fixed\n",
    "        so for each vector we have the same size.\n",
    "        \"\"\"\n",
    "        # torch.bmm is batched matrix multiplication\n",
    "        # this is basically xx' for calculating weights wij.\n",
    "        raw_weights = torch.bmm(x, x.transpose(1,2))\n",
    "        \n",
    "        # Turning these weights into probabilites by applying row-wise softmax\n",
    "        weights = F.softmax(raw_weights, dim=2)\n",
    "        \n",
    "        # y = wx to get the output vector of size (b, t, k)\n",
    "        y = torch.bmm(weights,x)\n",
    "        \n",
    "        return y\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
