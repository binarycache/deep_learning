{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from _utils_examples import fmnist_data, get_logpath\n",
    "from backpack import extend, extensions\n",
    "\n",
    "from cockpit import Cockpit, CockpitPlotter\n",
    "from cockpit.utils.configuration import configuration\n",
    "from cockpit.utils import schedules\n",
    "from PIL import Image\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from cockpit import quantities\n",
    "from cockpit.utils.configuration import quantities_cls_for_configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locate_json_log(testproblem, optimizer_class):\n",
    "    \"\"\"Locate json logfile.\"\"\"\n",
    "    RUN_DIR = os.path.join(HEREDIR, \"results\", testproblem, optimizer_class.__name__)\n",
    "    RUN_PATTERN = os.path.join(RUN_DIR, \"*/*__log.json\")\n",
    "    RUN_MATCH = glob.glob(RUN_PATTERN)\n",
    "    assert len(RUN_MATCH) == 1, f\"Found no or multiple files: {RUN_MATCH}\"\n",
    "    return RUN_MATCH[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testproblem = \"mnist_logreg\"\n",
    "optimizer_class = torch.optim.SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Fashion-MNIST classifier\n",
    "data = fmnist_data(batch_size=32)\n",
    "model = extend(torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(784, 10)))\n",
    "loss_fn = extend(torch.nn.CrossEntropyLoss(reduction=\"mean\"))\n",
    "individual_loss_fn = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "# Create SGD Optimizer\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "\n",
    "# Create Cockpit and a plotter\n",
    "# Customize the tracked quantities and their tracking schedule\n",
    "quantities = [\n",
    "    quantities.GradNorm(schedules.linear(interval=1)),\n",
    "    quantities.Distance(schedules.linear(interval=1)),\n",
    "    quantities.UpdateSize(schedules.linear(interval=1)),\n",
    "    quantities.HessMaxEV(schedules.linear(interval=3)),\n",
    "    quantities.GradHist1d(schedules.linear(interval=10), bins=10),\n",
    "]\n",
    "cockpit = Cockpit(model.parameters(), quantities=quantities)\n",
    "plotter = CockpitPlotter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda3/envs/torch/lib/python3.9/site-packages/torch/autograd/__init__.py:154: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at  /opt/conda/conda-bld/pytorch_1640811803361/work/torch/csrc/autograd/engine.cpp:976.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cockpit|plot] Saving figure in /data/github/deep_learning/pytorch/logfiles/cockpit_output/cockpit__primary__10.png\n",
      "[cockpit|plot] Saving figure in /data/github/deep_learning/pytorch/logfiles/cockpit_output/cockpit__primary__20.png\n",
      "[cockpit|plot] Saving figure in /data/github/deep_learning/pytorch/logfiles/cockpit_output/cockpit__primary__30.png\n",
      "[cockpit|plot] Saving figure in /data/github/deep_learning/pytorch/logfiles/cockpit_output/cockpit__primary__40.png\n",
      "[cockpit|plot] Saving figure in /data/github/deep_learning/pytorch/logfiles/cockpit_output/cockpit__primary__50.png\n",
      "[cockpit] writing output to /data/github/deep_learning/pytorch/logfiles/cockpit_output.json\n",
      "[cockpit|plot] Saving figure in /data/github/deep_learning/pytorch/logfiles/cockpit_output/cockpit__primary___final.png\n"
     ]
    }
   ],
   "source": [
    "# Main training loop\n",
    "max_steps, global_step = 50, 0\n",
    "for inputs, labels in iter(data):\n",
    "    opt.zero_grad()\n",
    "\n",
    "    # forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = loss_fn(outputs, labels)\n",
    "    losses = individual_loss_fn(outputs, labels)\n",
    "\n",
    "    # backward pass\n",
    "    with cockpit(\n",
    "        global_step,\n",
    "        extensions.DiagHessian(),  # Other BackPACK quantities can be computed as well\n",
    "        info={\n",
    "            \"batch_size\": inputs.shape[0],\n",
    "            \"individual_losses\": losses,\n",
    "            \"loss\": loss,\n",
    "            \"optimizer\": opt,\n",
    "        },\n",
    "    ):\n",
    "        loss.backward(create_graph=cockpit.create_graph(global_step))\n",
    "\n",
    "    # optimizer step\n",
    "    opt.step()\n",
    "    global_step += 1\n",
    "\n",
    "    if global_step % 10 == 0:\n",
    "        plotter.plot(\n",
    "            cockpit,\n",
    "            savedir=get_logpath(),\n",
    "            show_plot=False,\n",
    "            save_plot=True,\n",
    "            savename_append=str(global_step),\n",
    "        )\n",
    "\n",
    "    if global_step >= max_steps:\n",
    "        break\n",
    "\n",
    "# Write Cockpit to json file.\n",
    "cockpit.write(get_logpath())\n",
    "\n",
    "# Plot results from file\n",
    "plotter.plot(\n",
    "    get_logpath(),\n",
    "    savedir=get_logpath(),\n",
    "    show_plot=False,\n",
    "    save_plot=True,\n",
    "    savename_append=\"_final\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/github/deep_learning/pytorch/logfiles/cockpit_output\n"
     ]
    }
   ],
   "source": [
    "print(get_logpath())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "logpath = get_logpath()\n",
    "savedir = os.path.dirname(logpath)\n",
    "\n",
    "plotter = CockpitPlotter()\n",
    "\n",
    "# regenerate plots\n",
    "plotter._read_tracking_results(logpath)\n",
    "track_events = list(plotter.tracking_data[\"iteration\"])\n",
    "\n",
    "frame_paths = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['iteration', 'Distance', 'GradHist1d', 'GradNorm', 'HessMaxEV',\n",
       "       'UpdateSize'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotter.tracking_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting 00000/00050\n",
      "Plotting 00001/00050\n",
      "Plotting 00002/00050\n",
      "Plotting 00003/00050\n",
      "Plotting 00004/00050\n",
      "Plotting 00005/00050\n",
      "Plotting 00006/00050\n",
      "Plotting 00007/00050\n",
      "Plotting 00008/00050\n",
      "Plotting 00009/00050\n",
      "Plotting 00010/00050\n",
      "Plotting 00011/00050\n",
      "Plotting 00012/00050\n",
      "Plotting 00013/00050\n",
      "Plotting 00014/00050\n",
      "Plotting 00015/00050\n",
      "Plotting 00016/00050\n",
      "Plotting 00017/00050\n",
      "Plotting 00018/00050\n",
      "Plotting 00019/00050\n",
      "Plotting 00020/00050\n",
      "Plotting 00021/00050\n",
      "Plotting 00022/00050\n",
      "Plotting 00023/00050\n",
      "Plotting 00024/00050\n",
      "Plotting 00025/00050\n",
      "Plotting 00026/00050\n",
      "Plotting 00027/00050\n",
      "Plotting 00028/00050\n",
      "Plotting 00029/00050\n",
      "Plotting 00030/00050\n",
      "Plotting 00031/00050\n",
      "Plotting 00032/00050\n",
      "Plotting 00033/00050\n",
      "Plotting 00034/00050\n",
      "Plotting 00035/00050\n",
      "Plotting 00036/00050\n",
      "Plotting 00037/00050\n",
      "Plotting 00038/00050\n",
      "Plotting 00039/00050\n",
      "Plotting 00040/00050\n",
      "Plotting 00041/00050\n",
      "Plotting 00042/00050\n",
      "Plotting 00043/00050\n",
      "Plotting 00044/00050\n",
      "Plotting 00045/00050\n",
      "Plotting 00046/00050\n",
      "Plotting 00047/00050\n",
      "Plotting 00048/00050\n",
      "Plotting 00049/00050\n"
     ]
    }
   ],
   "source": [
    "for idx, global_step in enumerate(track_events):\n",
    "    print(f\"Plotting {idx:05d}/{len(track_events):05d}\")\n",
    "\n",
    "    plotter.plot(\n",
    "        logpath,\n",
    "        show_plot=False,\n",
    "        save_plot=False,\n",
    "        block=False,\n",
    "        show_log_iter=True,\n",
    "        discard=global_step,\n",
    "    )\n",
    "    this_frame_path = os.path.join(savedir, f\"animation_frame_{idx:05d}.png\")\n",
    "    plotter.fig.savefig(this_frame_path)\n",
    "    frame_paths.append(this_frame_path)\n",
    "\n",
    "frame, *frames = [Image.open(f) for f in frame_paths]\n",
    "\n",
    "animation_savepath = os.path.join(savedir, \"showcase.gif\")\n",
    "\n",
    "# Collect images and create Animation\n",
    "frame.save(\n",
    "    fp=animation_savepath,\n",
    "    format=\"GIF\",\n",
    "    append_images=frames,\n",
    "    save_all=True,\n",
    "    duration=200,\n",
    "    loop=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c207b5e043e2b6ee029cb1f3c7633378ed9ad895d49c50d408b3ba611a8a833e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
